# üß© The Gauntlet: Universal Paradox Engine

**Automated contradiction and paradox detection for any theoretical framework**

## üöÄ What's New

**Multi-AI Integration**: Direct API connection to any AI model you hold credentials for:
- **OpenAI** (GPT-4, GPT-3.5-turbo, etc.)
- **Anthropic** (Claude 3.5 Sonnet, Haiku, etc.) 
- **Google** (Gemini Pro, Gemini 1.5 Pro)
- **Ollama** (Local models: Llama, Mistral, etc.)

**Dual Engine Modes**:
1. **Theory Analysis Mode**: Analyzes YOUR arguments/theories for logical consistency
2. **AI Response Mode**: Analyzes AI responses for internal contradictions and evidence quality

Run in Google Colab or your preferred environment - just paste your API key and start testing!

## üéØ What The Gauntlet Does

Drop in your theory, paper, argument, or AI conversation. The engine will systematically analyze it for logical consistency, contradictions, and evidence quality.

**The AI Response Mode** specifically evaluates how well AI models reason through complex problems, detecting when they make unsupported claims or contradict themselves.

## üî• Domains Supported

- ‚öõÔ∏è **Physics** (cosmology, quantum gravity, relativity, alternative theories)
- ‚öñÔ∏è **Legal** (case law, precedents, statutory interpretation)
- üíº **Business** (strategies, economic models, market analysis)
- üß† **Philosophy** (metaphysics, ethics, logic, consciousness)
- üß¨ **Medicine** (clinical claims, research methodology)
- üìä **Data Science** (methodology, AI ethics, statistical reasoning)
- üåå **Cosmology** (dark matter alternatives, modified gravity, expansion models)

## üõ† Core Features

### Analysis Capabilities
- **Claim-by-claim breakdown**: Resolved / Partial / Failed status for each assertion
- **Contradiction detection**: Direct negations, circular logic, property mismatches
- **Evidence quality scoring**: 0‚Äì1 scale with citation counts and methodology assessment
- **Domain-specific analysis**: Tailored evaluation criteria for different fields
- **Mechanism resolution**: Checks if claims provide actual explanatory mechanisms

### Technical Features
- **JSON export** with complete analysis breakdown
- **Batch processing**: Upload multiple documents at once
- **Interactive menus**: Quick tests OR comprehensive deep dives
- **Cross-validation**: Test consistency across multiple AI providers
- **Real-time scoring**: Live feedback as analysis progresses

### AI Integration
- **Universal compatibility**: Works with any AI model via API
- **Response quality assessment**: Evaluates AI logical consistency
- **Bias detection**: Identifies when AIs treat theories as facts vs. testable models
- **Comparative analysis**: Test how different AI models handle the same problems

## ‚öîÔ∏è Why "The Gauntlet"?

Most people think their ideas are bulletproof ‚Äî until they run them through systematic logical analysis.

**Some theories survive** ‚úÖ (Strong evidence, consistent logic, clear mechanisms)
**Most don't** ‚ùå (Contradictions, weak evidence, circular reasoning)

The Gauntlet doesn't care about academic reputation, theoretical consensus, or how "established" an idea is. It only cares about logical consistency and evidence quality.

## üöÄ Quick Start Guide

### 1. Setup
```bash
# Run in Google Colab or local Jupyter
# Install requirements (handled automatically in notebook)
```

### 2. Choose Your Mode
- **Theory Analysis**: Test your own arguments and frameworks
- **AI Response Analysis**: Evaluate how well AIs reason through problems

### 3. Connect AI Provider (Optional)
- Paste API key for OpenAI, Anthropic, Google, or Ollama
- Or use standalone analysis mode

### 4. Run Analysis
- **Quick Test**: Paste text directly into interface
- **File Upload**: Upload documents for batch processing
- **Interactive Mode**: Step through analysis with detailed explanations

### 5. Get Results
- **Overall Status**: RESOLVES / PARTIAL / FAILS
- **Detailed Breakdown**: Claim-by-claim analysis
- **Evidence Assessment**: Quality scoring with explanations
- **Contradiction Report**: Specific logical problems identified
- **Export Options**: JSON, CSV, or formatted report

## üìä Sample Analysis Output

```
THEORY: "MBT geometric framework explains cosmological observations without dark energy"

OVERALL STATUS: RESOLVES ‚úÖ
CONFIDENCE: 87%
EVIDENCE QUALITY: 0.78/1.0

CLAIMS ANALYZED: 8
‚îú‚îÄ‚îÄ RESOLVED: 6 (Mathematical framework, observational fits, predictive success)
‚îú‚îÄ‚îÄ PARTIAL: 2 (Mechanism details, scope limitations)
‚îî‚îÄ‚îÄ FAILED: 0

CONTRADICTIONS: 0 detected
EVIDENCE TYPES: Mathematical, observational, statistical
MECHANISM PROVIDED: Yes - geometric expansion model with specific equations
```

## üéØ Perfect For

- **Researchers** testing alternative scientific theories
- **Students** checking argument logic before submission
- **Academics** peer-reviewing theoretical frameworks
- **AI Developers** evaluating model reasoning quality
- **Anyone** who wants to stress-test their ideas against rigorous analysis

## üî¨ Special Features for Scientific Research

- **Theory-neutral analysis**: Doesn't favor "established" theories over alternatives
- **Evidence-first approach**: Prioritizes data over theoretical consensus
- **Cross-framework comparison**: Compare competing theoretical approaches objectively
- **Assumption tracking**: Identifies hidden assumptions in arguments

## ‚ö° Advanced Usage

### Batch Mode
Upload multiple papers, theories, or AI conversations for systematic comparison.

### Custom Domains
Configure analysis criteria for specialized fields or novel theoretical frameworks.

### API Integration
Connect multiple AI providers to test how different models handle the same logical challenges.

### Export & Documentation
Generate comprehensive reports for academic or professional use.

## üéÆ Try These Examples

**Physics**: "Could General Relativity be fundamentally wrong about gravity?"
**Cosmology**: "Alternative theories vs. dark matter - which explains observations better?"
**AI Reasoning**: "How do different AI models handle paradoxical physics questions?"
**Logic**: "Test this argument for hidden contradictions and weak evidence"

## üö¶ Quality Levels

- **üü¢ RESOLVES**: Strong evidence, clear mechanisms, no contradictions
- **üü° PARTIAL**: Some issues but generally sound reasoning
- **üî¥ FAILS**: Significant contradictions, weak evidence, or circular logic

## üìù Note on AI Response Analysis

When analyzing AI responses, The Gauntlet evaluates the AI's reasoning process, not the human's input. This helps identify when AI models:
- Make unsupported claims
- Contradict themselves within responses  
- Treat theoretical models as absolute facts
- Provide evidence-free assertions
- Use circular reasoning

Perfect for researchers who need AI assistance but want to verify the logical quality of AI-generated analysis.

---

**Ready to test your ideas against rigorous logical analysis?**

*Some theories will survive. Most won't. Find out which category yours falls into.*
